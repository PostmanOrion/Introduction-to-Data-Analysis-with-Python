{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning 2\n",
    "## Course project          \n",
    "                                                 Author: Diego Rodriguez\n",
    "## Nonlinear classifiers\n",
    "Try with nonlinear classifiers, can you do better than the baseline models from above?\n",
    "- Try with a random Forest, does increasing the number of trees help?\n",
    "- Try with SVMs - does the RBF kernel perform better than the linear one?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_features', 'validation_features', 'test_features', 'train_labels', 'validation_labels', 'test_labels', 'train_pixels', 'validation_pixels', 'test_pixels']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the npz file\n",
    "base_dir = '/Users/rodriguezmod/Downloads/swissroads/'\n",
    "\n",
    "with np.load(base_dir+'features.npz', allow_pickle=False) as npz_file: \n",
    "    # It's a dictionary-like object \n",
    "    print(list(npz_file.keys()))\n",
    "    \n",
    "    # Load the arrays    \n",
    "    # Merging test and validation features data to use a cross-validation approach to model fitting.\n",
    "    X_tr = np.concatenate((npz_file['train_features'], npz_file['validation_features']))\n",
    "    X_tr_pixels = np.concatenate((npz_file['train_pixels'], npz_file['validation_pixels']))\n",
    "    y_tr = np.concatenate((npz_file['train_labels'], npz_file['validation_labels']))\n",
    "    # Reduce to 1-dim\n",
    "    y_tr = np.argmax(y_tr, axis=1)\n",
    "\n",
    "    X_te = npz_file['test_features']\n",
    "    X_te_pixels = npz_file['test_pixels']\n",
    "    y_te = npz_file['test_labels']\n",
    "    # Reduce to 1-dim\n",
    "    y_te = np.argmax(y_te, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFs performance\n",
    "Try with a random forest, does increasing the number of trees help? Yes, it is. Let's first analyze the result of a random forest model for a case of n_estimators = 1 and then for much higher values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 87.4%\n",
      "Test accuracy: 68.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a decision tree object\n",
    "rfc = RandomForestClassifier(\n",
    "         n_estimators=1, max_depth=12, random_state=0)\n",
    "\n",
    "# Fitting on train set\n",
    "rfc.fit(X_tr, y_tr)\n",
    "\n",
    "# Evaluate on train set\n",
    "accuracy_tr = rfc.score(X_tr, y_tr)\n",
    "\n",
    "# Evaluate on test set\n",
    "accuracy_te = rfc.score(X_te, y_te)\n",
    "\n",
    "# Print accuracy\n",
    "print('Train accuracy: {:.1f}%'.format(100*accuracy_tr))\n",
    "      \n",
    "# Print accuracy\n",
    "print('Test accuracy: {:.1f}%'.format(100*accuracy_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 100.0%\n",
      "Test accuracy: 88.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators'      : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 30, 100, 200],\n",
    "    'max_depth'         : [8, 9, 10, 11, 12],\n",
    "    #'random_state'      : [0],\n",
    "    #'max_features': ['auto'],\n",
    "    #'criterion' :['gini']\n",
    "}\n",
    "rfc_gscv = GridSearchCV(rfc, parameters, cv=10, n_jobs=10)\n",
    "\n",
    "# Fitting on train set\n",
    "rfc_gscv.fit(X_tr, y_tr)\n",
    "\n",
    "# Evaluate on train set\n",
    "accuracy_tr = rfc_gscv.score(X_tr, y_tr)\n",
    "\n",
    "# Evaluate on test set\n",
    "accuracy_te = rfc_gscv.score(X_te, y_te)\n",
    "\n",
    "# Print accuracy\n",
    "print('Train accuracy: {:.1f}%'.format(100*accuracy_tr))\n",
    "      \n",
    "# Print accuracy\n",
    "print('Test accuracy: {:.1f}%'.format(100*accuracy_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest classifier model an accuracy value of **68.0%** with n_estimators = 1, which is acceptable but not better value. With a random forest classifier model with n_estimators highers values, an accuracy value of **88.0%** is obtained, it shows that increasing the number of trees help to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble size effect\n",
    "Try with SVMs - does the RBF kernel perform better than the linear one? It does not do better, but anyway the values obtained are very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 100.0%\n",
      "Test accuracy: 92.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Create SVM with linear kernel\n",
    "linear_svc = LinearSVC()\n",
    "\n",
    "# Fitting on train set\n",
    "linear_svc.fit(X_tr, y_tr)\n",
    "\n",
    "# Evaluate on train set\n",
    "accuracy_tr = linear_svc.score(X_tr, y_tr)\n",
    "\n",
    "# Evaluate on test set\n",
    "accuracy_te = linear_svc.score(X_te, y_te)\n",
    "\n",
    "# Print accuracy\n",
    "print('Train accuracy: {:.1f}%'.format(100*accuracy_tr))\n",
    "      \n",
    "# Print accuracy\n",
    "print('Test accuracy: {:.1f}%'.format(100*accuracy_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 99.3%\n",
      "Test accuracy: 94.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create SVM with RBF kernel\n",
    "rbf_svc_c1 = SVC(kernel='rbf', C=1)\n",
    "\n",
    "# Fitting on train set\n",
    "rbf_svc_c1.fit(X_tr, y_tr)\n",
    "\n",
    "# Evaluate on train set\n",
    "accuracy_tr = rbf_svc_c1.score(X_tr, y_tr)\n",
    "\n",
    "# Evaluate on test set\n",
    "accuracy_te = rbf_svc_c1.score(X_te, y_te)\n",
    "\n",
    "# Print accuracy\n",
    "print('Train accuracy: {:.1f}%'.format(100*accuracy_tr))\n",
    "      \n",
    "# Print accuracy\n",
    "print('Test accuracy: {:.1f}%'.format(100*accuracy_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear, RBF SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting a random forest classifier model an accuracy value of **68.0%** is obtained, which is not a good value. With a random forest classifier model with cross-validation estimator, an accuracy value of **88.0%** is obtained, it is a really good value, it is better than the one obtained previously. \n",
    "\n",
    "Finally, with a support vector classification (SVM) object get a value of accuracy of **92.0%** getting a good value. support vector classification (SVM) with linear kernel object get a value of accuracy of **94.0%**. Both values show an improvement of the accuracy value using SVM model (with or without kernel), but even so, it is the best value obtained by random forest classifier model with cross-validation estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
